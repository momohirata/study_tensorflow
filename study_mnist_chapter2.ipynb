{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "study_mnist_chapter2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/momohirata/study_tensorflow/blob/master/study_mnist_chapter2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "39-GzBD-6RtX",
        "colab_type": "code",
        "outputId": "8b8a79da-718c-406f-e22d-4b69cda37b32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "import tensorflow as tf\n",
        "\n",
        "### MNISTデータを格納したオブジェクトを呼び出す\n",
        "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
        "\n",
        "\n",
        "#------- 全訓練データの取得----------\n",
        "# 訓練用の入力データ、正解データをミニバッチを指定して取得\n",
        "train_images, train_labels = mnist.train.next_batch(50)\n",
        "\n",
        "# テスト用の全画像データを取得\n",
        "test_images = mnist.test.images\n",
        "\n",
        "# テスト用の全正解データを取得\n",
        "test_labels = mnist.test.labels\n",
        "#---------------------------------\n",
        "\n",
        "\n",
        "#------------順伝播----------------\n",
        "# 入力データを定義\n",
        "# [ミニバッチサイズ(まだわからないのでNone), 1枚の画像の画素数(画素数)]の行列\n",
        "x = tf.placeholder(tf.float32, [None,784]) \n",
        "\n",
        "\n",
        "### 入力層から中間層\n",
        "# 正規分布からランダムに取り出したテンソルを生成\n",
        "# 入力層のユニット数:784, 中間層のユニット数:64\n",
        "w_1 = tf.Variable(tf.truncated_normal([784,64],stddev=0.1),name=\"weight1\")\n",
        "\n",
        "# [1, 64]のテンソルにしておけば、tensorflowがいい感じに計算してくれる\n",
        "b_1 = tf.Variable(tf.zeros([64]),name=\"bias1\")\n",
        "\n",
        "# 入力[バッチサイズ, 784] * 重み[784, 64] + バイアス= [バッチサイズ, 64]\n",
        "# relu関数: 0以下→0, 0以上→そのまま出力\n",
        "h_1 = tf.nn.relu(tf.matmul(x,w_1) + b_1)\n",
        "\n",
        "\n",
        "### 中間層から出力層\n",
        "# 出力層のユニット数:10\n",
        "w_2 = tf.Variable(tf.truncated_normal([64, 10], stddev=0.1), name=\"w2\")\n",
        "b_2 = tf.Variable(tf.zeros([10]), name = \"b2\")\n",
        "\n",
        "# softmax関数:出力される各成分を0~1、すべての成分の和を1にしてくれる確率を表現する関数\n",
        "out = tf.nn.softmax(tf.matmul(h_1, w_2) + b_2)\n",
        "#--------------------------------\n",
        "\n",
        "#---------誤差関数、訓練-----------\n",
        "# 誤差関数\n",
        "# 正解データ[None(ミニバッチサイズ), 出力層のユニット数]\n",
        "y = tf.placeholder(tf.float32, [None, 10])\n",
        "# 出力結果との差を求める → それを2乗して二乗誤差を求める → 全二乗誤差を平均\n",
        "loss = tf.reduce_mean(tf.square(y - out))\n",
        "\n",
        "# 訓練\n",
        "# 確率的勾配降下法(学習率:0.5)\n",
        "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
        "#--------------------------------\n",
        "\n",
        "\n",
        "#-------------評価----------------\n",
        "# 評価\n",
        "# 正解データ、出力データから最大値は何番目かを取得(一番確率の列(0~9)を求める)\n",
        "# [バッチサイズ, 1]の行列を作成 → 出力データが正解かどうか判定 → 正解率を求める\n",
        "correct = tf.equal(tf.argmax(out, 1), tf.argmax(y,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
        "#--------------------------------\n",
        "\n",
        "\n",
        "# 実行\n",
        "\n",
        "# 変数の初期化\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  #初期化を実行\n",
        "  sess.run(init)\n",
        "\n",
        "  # テスト用データをロード\n",
        "  test_images = mnist.test.images\n",
        "  test_labels = mnist.test.labels\n",
        "  \n",
        "  for i in range(1000):\n",
        "    step = i + 1\n",
        "    train_images, train_labels = mnist.train.next_batch(50) #ミニバッチサイズ50\n",
        "    # ミニバッチ取得 → placeholderへ渡す → train_step実行\n",
        "    sess.run(train_step, feed_dict={x:train_images, y:train_labels})\n",
        "    \n",
        "    # 10stepごとに精度を確認\n",
        "    if step % 10 == 0:\n",
        "      acc_val = sess.run(accuracy, feed_dict = {x:test_images, y:test_labels})\n",
        "      print('Step %d: accuracy = %.2f' % (step, acc_val))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0708 08:33:56.829746 139765075380096 deprecation.py:323] From <ipython-input-1-9cef5202cfd3>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "W0708 08:33:56.831489 139765075380096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "W0708 08:33:56.832542 139765075380096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0708 08:33:57.136200 139765075380096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "W0708 08:33:57.139168 139765075380096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "W0708 08:33:57.201957 139765075380096 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
            "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
            "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
            "Step 10: accuracy = 0.08\n",
            "Step 20: accuracy = 0.11\n",
            "Step 30: accuracy = 0.15\n",
            "Step 40: accuracy = 0.20\n",
            "Step 50: accuracy = 0.24\n",
            "Step 60: accuracy = 0.29\n",
            "Step 70: accuracy = 0.33\n",
            "Step 80: accuracy = 0.34\n",
            "Step 90: accuracy = 0.35\n",
            "Step 100: accuracy = 0.40\n",
            "Step 110: accuracy = 0.41\n",
            "Step 120: accuracy = 0.44\n",
            "Step 130: accuracy = 0.44\n",
            "Step 140: accuracy = 0.47\n",
            "Step 150: accuracy = 0.50\n",
            "Step 160: accuracy = 0.52\n",
            "Step 170: accuracy = 0.53\n",
            "Step 180: accuracy = 0.57\n",
            "Step 190: accuracy = 0.59\n",
            "Step 200: accuracy = 0.63\n",
            "Step 210: accuracy = 0.63\n",
            "Step 220: accuracy = 0.65\n",
            "Step 230: accuracy = 0.68\n",
            "Step 240: accuracy = 0.69\n",
            "Step 250: accuracy = 0.70\n",
            "Step 260: accuracy = 0.70\n",
            "Step 270: accuracy = 0.71\n",
            "Step 280: accuracy = 0.72\n",
            "Step 290: accuracy = 0.73\n",
            "Step 300: accuracy = 0.74\n",
            "Step 310: accuracy = 0.75\n",
            "Step 320: accuracy = 0.76\n",
            "Step 330: accuracy = 0.76\n",
            "Step 340: accuracy = 0.77\n",
            "Step 350: accuracy = 0.78\n",
            "Step 360: accuracy = 0.79\n",
            "Step 370: accuracy = 0.79\n",
            "Step 380: accuracy = 0.79\n",
            "Step 390: accuracy = 0.81\n",
            "Step 400: accuracy = 0.81\n",
            "Step 410: accuracy = 0.82\n",
            "Step 420: accuracy = 0.83\n",
            "Step 430: accuracy = 0.83\n",
            "Step 440: accuracy = 0.82\n",
            "Step 450: accuracy = 0.83\n",
            "Step 460: accuracy = 0.84\n",
            "Step 470: accuracy = 0.83\n",
            "Step 480: accuracy = 0.84\n",
            "Step 490: accuracy = 0.84\n",
            "Step 500: accuracy = 0.84\n",
            "Step 510: accuracy = 0.84\n",
            "Step 520: accuracy = 0.85\n",
            "Step 530: accuracy = 0.85\n",
            "Step 540: accuracy = 0.85\n",
            "Step 550: accuracy = 0.85\n",
            "Step 560: accuracy = 0.86\n",
            "Step 570: accuracy = 0.86\n",
            "Step 580: accuracy = 0.86\n",
            "Step 590: accuracy = 0.86\n",
            "Step 600: accuracy = 0.86\n",
            "Step 610: accuracy = 0.86\n",
            "Step 620: accuracy = 0.86\n",
            "Step 630: accuracy = 0.87\n",
            "Step 640: accuracy = 0.87\n",
            "Step 650: accuracy = 0.87\n",
            "Step 660: accuracy = 0.87\n",
            "Step 670: accuracy = 0.87\n",
            "Step 680: accuracy = 0.87\n",
            "Step 690: accuracy = 0.87\n",
            "Step 700: accuracy = 0.87\n",
            "Step 710: accuracy = 0.87\n",
            "Step 720: accuracy = 0.87\n",
            "Step 730: accuracy = 0.88\n",
            "Step 740: accuracy = 0.88\n",
            "Step 750: accuracy = 0.88\n",
            "Step 760: accuracy = 0.88\n",
            "Step 770: accuracy = 0.88\n",
            "Step 780: accuracy = 0.88\n",
            "Step 790: accuracy = 0.88\n",
            "Step 800: accuracy = 0.88\n",
            "Step 810: accuracy = 0.88\n",
            "Step 820: accuracy = 0.88\n",
            "Step 830: accuracy = 0.89\n",
            "Step 840: accuracy = 0.88\n",
            "Step 850: accuracy = 0.89\n",
            "Step 860: accuracy = 0.88\n",
            "Step 870: accuracy = 0.88\n",
            "Step 880: accuracy = 0.88\n",
            "Step 890: accuracy = 0.89\n",
            "Step 900: accuracy = 0.89\n",
            "Step 910: accuracy = 0.88\n",
            "Step 920: accuracy = 0.88\n",
            "Step 930: accuracy = 0.88\n",
            "Step 940: accuracy = 0.89\n",
            "Step 950: accuracy = 0.89\n",
            "Step 960: accuracy = 0.89\n",
            "Step 970: accuracy = 0.89\n",
            "Step 980: accuracy = 0.89\n",
            "Step 990: accuracy = 0.89\n",
            "Step 1000: accuracy = 0.89\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}